{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense,Flatten,Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VGG16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayanth\\AppData\\Roaming\\Python\\Python310\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (5.0.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(horizontal_flip=True, shear_range=0.2, rescale=1./255)\n",
    "test_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1238 images belonging to 4 classes.\n",
      "Found 326 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_gen.flow_from_directory(\"D:\\Ai-Learning\\Animal_Dataset\\dataset\\Training\", target_size=(224, 224), batch_size=25, class_mode='categorical')\n",
    "test = test_gen.flow_from_directory(\"D:\\Ai-Learning\\Animal_Dataset\\dataset\\Testing\", target_size=(224, 224), batch_size=25, class_mode='categorical')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 114s 2us/step\n",
      "58900480/58889256 [==============================] - 114s 2us/step\n"
     ]
    }
   ],
   "source": [
    "my_vgg = VGG16(include_top=False, weights='imagenet',input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in my_vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding our own layers:\n",
    "\n",
    "# output of my_vgg layer we add flatten layer\n",
    "out_of_vgg = Flatten()(my_vgg.output)\n",
    "\n",
    "# output of that flatten layer we add dense layer\n",
    "out_of_dense = Dense(4, activation='softmax')(out_of_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the model\n",
    "\n",
    "model = Model(inputs=my_vgg.input, outputs=out_of_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model:\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jayanth\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "50/50 [==============================] - 231s 5s/step - loss: 0.6436 - accuracy: 0.7754 - val_loss: 0.1551 - val_accuracy: 0.9356\n",
      "Epoch 2/5\n",
      "50/50 [==============================] - 231s 5s/step - loss: 0.1229 - accuracy: 0.9669 - val_loss: 0.0790 - val_accuracy: 0.9816\n",
      "Epoch 3/5\n",
      "50/50 [==============================] - 233s 5s/step - loss: 0.0654 - accuracy: 0.9863 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "50/50 [==============================] - 305s 6s/step - loss: 0.0383 - accuracy: 0.9960 - val_loss: 0.0232 - val_accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "50/50 [==============================] - 330s 7s/step - loss: 0.0356 - accuracy: 0.9935 - val_loss: 0.0305 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a546fae770>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# training the model:\n",
    "model.fit(train,validation_data=test ,epochs=5, batch_size=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bear\n",
      "crow\n",
      "elephant\n",
      "rat\n"
     ]
    }
   ],
   "source": [
    "# model - testing\n",
    "\n",
    "output = ['bear', 'crow', 'elephant', 'rat']\n",
    "def func(str):\n",
    "    img = image.load_img(str, target_size=(224,224))\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "img = func('DataSets/AnimalPredict/bear.jpg')\n",
    "print(output[np.argmax(model.predict(img))])\n",
    "\n",
    "img = func('DataSets/AnimalPredict/crow.jpg')\n",
    "print(output[np.argmax(model.predict(img))])\n",
    "\n",
    "img = func('DataSets/AnimalPredict/elephant.jpg')\n",
    "print(output[np.argmax(model.predict(img))])\n",
    "\n",
    "img = func('DataSets/AnimalPredict/rat.jpg')\n",
    "print(output[np.argmax(model.predict(img))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('D:/Ai-Learning/animal-vgg.h5')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### similarly we can do with other models:\n",
    "#### well know models: \n",
    "#### 1. ResNet50\n",
    "#### 2. Inception\n",
    "#### 3. Xception\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
